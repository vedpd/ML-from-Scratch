{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7D4wce4F17Agd4FhYSVHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedpd/ML-from-Scratch/blob/main/LogisticRegression_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3ecLjEEGwDJA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegression:\n",
        "  def __init__(self,learning_rate=0.01,num_epochs=1000):\n",
        "    self.learning_rate= learning_rate\n",
        "    self.num_epochs = num_epochs\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "  def initialize_weights(self,num_features):\n",
        "    self.weights = np.zeros((num_features,1))\n",
        "    self.bias = 0\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.sigmoid(np.dot(X,self.weights) + self.bias)\n",
        "\n",
        "  def compute_loss(self, y_true , y_pred):\n",
        "    m = len(y_true)\n",
        "    loss = -np.mean(y_true * np.log(y_pred) + (1-y_true) * np.log(1-y_pred))\n",
        "    return loss\n",
        "\n",
        "  def backward(self, X, y_true, y_pred):\n",
        "    m = len(y_true)\n",
        "    dw = np.dot(X.T , (y_pred - y_true)) / m\n",
        "    db = np.mean(y_pred - y_true)\n",
        "\n",
        "    return dw,db\n",
        "\n",
        "  def train(self, X, y):\n",
        "    num_samples, num_features = X.shape\n",
        "    self.initialize_weights(num_features)\n",
        "\n",
        "    for epoch in range(self.num_epochs):\n",
        "\n",
        "      #Forward pass\n",
        "      y_pred = self.forward(X)\n",
        "\n",
        "      # compute loss\n",
        "      loss = self.compute_loss(y, y_pred)\n",
        "\n",
        "      #Backprop\n",
        "      dw, db = self.backward(X,y,y_pred)\n",
        "\n",
        "      #weight update\n",
        "\n",
        "      self.weights -= self.learning_rate * dw\n",
        "      self.bias -= self.learning_rate * db\n",
        "\n",
        "      if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch} , Loss :{loss}')\n",
        "\n",
        "  def predict(self, X):\n",
        "     y_pred = self.forward(X)\n",
        "     return (y_pred >=0.5).astype(int)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ ==\"__main__\":\n",
        "  np.random.seed(0)\n",
        "  X = np.random.randn(100,2)\n",
        "  y=np.random.randint(0,2,size=(100,1))\n",
        "\n",
        "  model = LogisticRegression()\n",
        "  model.train(X,y)\n",
        "\n",
        "\n",
        "  y_pred = model.predict(X)\n",
        "  print(\"Predictions:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8S_nuL55yl_",
        "outputId": "0baacb53-6194-4bf8-acfe-6820e2f294b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 , Loss :0.6931471805599453\n",
            "Epoch 100 , Loss :0.6886351153004913\n",
            "Epoch 200 , Loss :0.6859595481577279\n",
            "Epoch 300 , Loss :0.6843598984588277\n",
            "Epoch 400 , Loss :0.6833952043517147\n",
            "Epoch 500 , Loss :0.6828085142761569\n",
            "Epoch 600 , Loss :0.6824488859036749\n",
            "Epoch 700 , Loss :0.6822268361516722\n",
            "Epoch 800 , Loss :0.6820888249084827\n",
            "Epoch 900 , Loss :0.6820025325865602\n",
            "Predictions: [[1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCoo-Lc46POT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}